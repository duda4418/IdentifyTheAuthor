{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 107840,
          "databundleVersionId": 13063981,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 12558216,
          "sourceType": "datasetVersion",
          "datasetId": 7929775
        },
        {
          "sourceId": 12558343,
          "sourceType": "datasetVersion",
          "datasetId": 7929861
        },
        {
          "sourceId": 12558352,
          "sourceType": "datasetVersion",
          "datasetId": 7929783
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === Standardized path configuration added automatically ===\n",
        "from pathlib import Path\n",
        "BASE_DIR = Path.cwd()  # project root when running the notebook\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "TRAIN_CSV = DATA_DIR / 'train' / 'train.csv'\n",
        "TEST_CSV = DATA_DIR / 'test' / 'test.csv'\n",
        "# You can now use TRAIN_CSV and TEST_CSV instead of hardcoded strings.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Load test predictions\ndeberta = pd.read_csv(\"/kaggle/input/preds-data/deberta_base_test_preds.csv\")\nroberta = pd.read_csv(\"/kaggle/input/preds-data/roberta_base_test_preds.csv\")\ntfidf = pd.read_csv(\"/kaggle/input/preds-data/submission_tfidf_single (11).csv\")\n\n# Blend predictions\nblend = (\n    0.55 * deberta[['deberta_base_EAP', 'deberta_base_HPL', 'deberta_base_MWS']].values +\n    0.15 * roberta[['roberta_base_EAP', 'roberta_base_HPL', 'roberta_base_MWS']].values +\n    0.30 * tfidf[['EAP', 'HPL', 'MWS']].values\n)\n# blend = (\n#     0.49 * deberta[['deberta_base_EAP', 'deberta_base_HPL', 'deberta_base_MWS']].values +\n#     0.20 * roberta[['roberta_base_EAP', 'roberta_base_HPL', 'roberta_base_MWS']].values +\n#     0.30 * tfidf[['EAP', 'HPL', 'MWS']].values\n# )\n# Create final submission\nsubmission = pd.DataFrame(blend, columns=['EAP', 'HPL', 'MWS'])\nsubmission.insert(0, 'id', deberta['id'])\nsubmission.to_csv(\"submission_blend.csv\", index=False)\n\nprint(\"âœ… submission_blend.csv created!\")\n",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T19:53:03.795974Z",
          "iopub.execute_input": "2025-07-23T19:53:03.796658Z",
          "iopub.status.idle": "2025-07-23T19:53:03.889353Z",
          "shell.execute_reply.started": "2025-07-23T19:53:03.796616Z",
          "shell.execute_reply": "2025-07-23T19:53:03.888365Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\n\n# === Load OOF predictions ===\ndeberta_oof = pd.read_csv(\"/kaggle/input/oof-preds/debertav3-base_oof.csv\")\nroberta_oof = pd.read_csv(\"/kaggle/input/oof-preds/roberta_oof_preds.csv\")\ntfidf_oof = pd.read_csv(\"/kaggle/input/oof-preds/oof_preds.csv\")\n\n# === Rename TF-IDF columns to prevent name collision ===\ntfidf_oof = tfidf_oof.rename(columns={\n    'roberta_base_EAP': 'EAP_tfidf',\n    'roberta_base_HPL': 'HPL_tfidf',\n    'roberta_base_MWS': 'MWS_tfidf'\n})\n\n# === Merge on ID ===\nmeta_df = deberta_oof.merge(roberta_oof, on='id')\nmeta_df = meta_df.merge(tfidf_oof, on='id')\n\n# === Generate pseudo-labels from DeBERTa OOF (or replace with true labels if available) ===\nmeta_df['label'] = meta_df[['debertav3-base_EAP', 'debertav3-base_HPL', 'debertav3-base_MWS']].values.argmax(axis=1)\n\n# === Prepare train data ===\nX_meta = meta_df.drop(columns=['id', 'label'])\ny_meta = meta_df['label']\n\n# === Train Logistic Regression with 5-Fold CV ===\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nmeta_preds_oof = np.zeros((len(X_meta), 3))\n\nfor train_idx, val_idx in cv.split(X_meta, y_meta):\n    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=5000)\n    clf.fit(X_meta.iloc[train_idx], y_meta.iloc[train_idx])\n    meta_preds_oof[val_idx] = clf.predict_proba(X_meta.iloc[val_idx])\n\n# === Evaluate\nprint(\"âœ… Meta-model OOF log loss:\", log_loss(y_meta, meta_preds_oof))\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T20:14:27.730631Z",
          "iopub.execute_input": "2025-07-23T20:14:27.731024Z",
          "iopub.status.idle": "2025-07-23T20:14:28.359474Z",
          "shell.execute_reply.started": "2025-07-23T20:14:27.730995Z",
          "shell.execute_reply": "2025-07-23T20:14:28.356881Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nimport pandas as pd\n\n# === Load test set base model predictions ===\ndeberta_test = pd.read_csv(\"/kaggle/input/preds-data/debertav3-base_best_preds.csv\")\nroberta_test = pd.read_csv(\"/kaggle/input/preds-data/roberta_base_test_preds.csv\")\ntfidf_test = pd.read_csv(\"/kaggle/input/preds-data/submission_tfidf_single (11).csv\")\n\n# âœ… Rename TF-IDF columns to match training set\ntfidf_test = tfidf_test.rename(columns={\n    'EAP': 'EAP_tfidf',\n    'HPL': 'HPL_tfidf',\n    'MWS': 'MWS_tfidf'\n})\n\n# === Merge test features in same order\nmeta_test = deberta_test.merge(roberta_test, on='id')\nmeta_test = meta_test.merge(tfidf_test, on='id')\nX_test_meta = meta_test.drop(columns=['id'])\n\n# === Fit final model on full OOF\nfinal_meta_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=5000)\nfinal_meta_model.fit(X_meta, y_meta)\n\n# === Predict\ntest_preds_meta = final_meta_model.predict_proba(X_test_meta)\n\n# === Create submission\nsubmission = pd.DataFrame(test_preds_meta, columns=['EAP', 'HPL', 'MWS'])\nsubmission.insert(0, 'id', meta_test['id'])\nsubmission.to_csv(\"submission_lgstack.csv\", index=False)\n\nprint(\"âœ… submission_lgstack.csv created successfully!\")\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T20:17:14.292594Z",
          "iopub.execute_input": "2025-07-23T20:17:14.292952Z",
          "iopub.status.idle": "2025-07-23T20:17:14.579697Z",
          "shell.execute_reply.started": "2025-07-23T20:17:14.292927Z",
          "shell.execute_reply": "2025-07-23T20:17:14.578826Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "!pip install lightgbm -q\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T20:19:45.407834Z",
          "iopub.execute_input": "2025-07-23T20:19:45.408245Z",
          "iopub.status.idle": "2025-07-23T20:19:50.637511Z",
          "shell.execute_reply.started": "2025-07-23T20:19:45.408220Z",
          "shell.execute_reply": "2025-07-23T20:19:50.636383Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import lightgbm as lgb\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom lightgbm import early_stopping\n\n# === LightGBM Stacking Training ===\noof_preds_lgb = np.zeros((len(X_meta), 3))\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(cv.split(X_meta, y_meta)):\n    print(f\"ðŸŸ¢ Fold {fold+1}\")\n    train_set = lgb.Dataset(X_meta.iloc[train_idx], label=y_meta.iloc[train_idx])\n    val_set = lgb.Dataset(X_meta.iloc[val_idx], label=y_meta.iloc[val_idx])\n\n    params = {\n        \"objective\": \"multiclass\",\n        \"num_class\": 3,\n        \"metric\": \"multi_logloss\",\n        \"verbosity\": 1,\n        \"seed\": 42,\n    }\n\n    model = lgb.train(\n        params,\n        train_set,\n        num_boost_round=1000,\n        valid_sets=[train_set, val_set],\n        valid_names=[\"train\", \"val\"],\n        callbacks=[early_stopping(stopping_rounds=50)]\n    )\n\n    oof_preds_lgb[val_idx] = model.predict(X_meta.iloc[val_idx])\n\nlogloss = log_loss(y_meta, oof_preds_lgb)\nprint(f\"âœ… LightGBM Meta-Model OOF Log Loss: {logloss:.5f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport lightgbm as lgb\nfrom lightgbm import early_stopping\nimport numpy as np\n\n# === Load test predictions from base models\ndeberta_test = pd.read_csv(\"/kaggle/input/preds-data/debertav3-base_best_preds.csv\")\nroberta_test = pd.read_csv(\"/kaggle/input/preds-data/roberta_base_test_preds.csv\")\ntfidf_test = pd.read_csv(\"/kaggle/input/preds-data/submission_tfidf_single (11).csv\")\n# === Rename TF-IDF columns to match training\ntfidf_test = tfidf_test.rename(columns={\n    'roberta_base_EAP': 'EAP_tfidf',\n    'roberta_base_HPL': 'HPL_tfidf',\n    'roberta_base_MWS': 'MWS_tfidf'\n})\n\n# === Merge test features\nmeta_test = deberta_test.merge(roberta_test, on='id')\nmeta_test = meta_test.merge(tfidf_test, on='id')\nX_test_meta = meta_test.drop(columns=['id'])\n\n# === Train LightGBM meta-model on full OOF data\ntrain_set = lgb.Dataset(X_meta, label=y_meta)\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"num_class\": 3,\n    \"metric\": \"multi_logloss\",\n    \"verbosity\": 1,\n    \"seed\": 42,\n}\n\nfinal_model = lgb.train(\n    params,\n    train_set,\n    num_boost_round=200,\n)\n\n# === Predict on test set\ntest_preds_lgb = final_model.predict(X_test_meta)\n\n# === Create submission\nsubmission = pd.DataFrame(test_preds_lgb, columns=['EAP', 'HPL', 'MWS'])\nsubmission.insert(0, 'id', meta_test['id'])\nsubmission.to_csv(\"submission_lgbstack.csv\", index=False)\n\nprint(\"âœ… submission_lgbstack.csv created successfully!\")\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T20:26:07.675002Z",
          "iopub.execute_input": "2025-07-23T20:26:07.676033Z",
          "iopub.status.idle": "2025-07-23T20:26:10.061850Z",
          "shell.execute_reply.started": "2025-07-23T20:26:07.675993Z",
          "shell.execute_reply": "2025-07-23T20:26:10.060920Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.preprocessing import StandardScaler\n\n# Load submission files\ndeberta = pd.read_csv('/kaggle/input/final-model-data/deberta_final.csv')\nroberta = pd.read_csv('/kaggle/input/final-model-data/deberta_final.csv')\nlr = pd.read_csv('/kaggle/input/final-model-data/LR_submission_tfidf_single.csv')\n\n# Rename columns to avoid clashes\ndeberta = deberta.rename(columns={\"EAP\": \"EAP_deb\", \"HPL\": \"HPL_deb\", \"MWS\": \"MWS_deb\"})\nroberta = roberta.rename(columns={\"EAP\": \"EAP_rob\", \"HPL\": \"HPL_rob\", \"MWS\": \"MWS_rob\"})\nlr = lr.rename(columns={\"EAP\": \"EAP_lr\", \"HPL\": \"HPL_lr\", \"MWS\": \"MWS_lr\"})\n\n# Merge on 'id'\nmerged = deberta.merge(roberta, on=\"id\").merge(lr, on=\"id\")\n\n# Features and pseudo-targets (averaged soft labels)\nX = merged.drop(columns=\"id\")\nX_scaled = StandardScaler().fit_transform(X)\n\ny_EAP = merged[[\"EAP_deb\", \"EAP_rob\", \"EAP_lr\"]].mean(axis=1)\ny_HPL = merged[[\"HPL_deb\", \"HPL_rob\", \"HPL_lr\"]].mean(axis=1)\ny_MWS = merged[[\"MWS_deb\", \"MWS_rob\", \"MWS_lr\"]].mean(axis=1)\n\n# Train RidgeCV regressors\nridge_eap = RidgeCV().fit(X_scaled, y_EAP)\nridge_hpl = RidgeCV().fit(X_scaled, y_HPL)\nridge_mws = RidgeCV().fit(X_scaled, y_MWS)\n\n# Predict and normalize\neap_pred = ridge_eap.predict(X_scaled)\nhpl_pred = ridge_hpl.predict(X_scaled)\nmws_pred = ridge_mws.predict(X_scaled)\n\ntotal = eap_pred + hpl_pred + mws_pred\nsubmission = pd.DataFrame({\n    \"id\": merged[\"id\"],\n    \"EAP\": eap_pred / total,\n    \"HPL\": hpl_pred / total,\n    \"MWS\": mws_pred / total\n})\n\n# Save final submission\nsubmission.to_csv(\"submission.csv\", index=False)\n",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T20:30:29.691834Z",
          "iopub.execute_input": "2025-07-23T20:30:29.692198Z",
          "iopub.status.idle": "2025-07-23T20:30:29.866486Z",
          "shell.execute_reply.started": "2025-07-23T20:30:29.692173Z",
          "shell.execute_reply": "2025-07-23T20:30:29.865538Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}